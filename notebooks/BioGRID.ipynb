{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b137a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import NamedTuple, Dict, List, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "\n",
    "import leidenalg\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import nxBuildGraph, from_ig_to_nx_partition_multiplex, from_part_to_list, fusion_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f891c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_STORAGE = r'../Data/'\n",
    "FILE_NAMES = ['candida_genetic', 'drosophila_genetic', 'homo_genetic', 'mus_genetic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402dbbbe",
   "metadata": {},
   "source": [
    "### 1. Data Reading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3f545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "layers_info = {}\n",
    "for _, file in enumerate(FILE_NAMES):\n",
    "    with open(DATA_STORAGE + file + '_layers.txt') as f:\n",
    "        lines = f.readlines()[1:]\n",
    "    layers = {}\n",
    "    if _ == 0:\n",
    "        for idx, layer in enumerate(lines):\n",
    "            dictionary[re.sub(r'[\\s\\d]', '', layer)] = idx\n",
    "\n",
    "    for idx, layer in enumerate(lines):\n",
    "        layers[idx] = dictionary[re.sub(r'[\\s\\d]', '', layer)]\n",
    "    layers_info[file] = layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a5fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_multiplex_edges_list = {}\n",
    "for _, file in enumerate(FILE_NAMES):\n",
    "    with open(DATA_STORAGE + file + '_multiplex.edges') as f:\n",
    "        lines = f.readlines()\n",
    "    edges = {}\n",
    "    for row in lines:\n",
    "        edge = re.findall(r'\\d+', row)\n",
    "        \n",
    "        key = layers_info[file][int(edge[0])-1]\n",
    "        edge = [int(i) for i in edge[1:-1]]\n",
    "        if key not in edges.keys():\n",
    "            edges[key] = []\n",
    "        edges[key].append(edge)\n",
    "        \n",
    "    graphs_multiplex_edges_list[file] = edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be3e6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_multiplex_nx = {}\n",
    "for name in graphs_multiplex_edges_list:\n",
    "    graphs_multiplex_nx[name] = nxBuildGraph(graphs_multiplex_edges_list[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ec1359",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_multiplex_ig = {}\n",
    "for name in graphs_multiplex_nx:\n",
    "    graphs_multiplex_ig[name] = list(map(lambda x: ig.Graph.from_networkx(x), graphs_multiplex_nx[name])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7b4952",
   "metadata": {},
   "source": [
    "### 2. Define Brute Force Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fcecbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, combinations_with_replacement, permutations\n",
    "step_size = 10\n",
    "alph_count = 7\n",
    "\n",
    "alphas = np.asarray(list(combinations_with_replacement([i for i in range(step_size)], alph_count)))\n",
    "alphas = alphas[alphas.sum(1) == step_size]\n",
    "\n",
    "permutation_len = math.factorial(alph_count)\n",
    "full_alphas = np.zeros((alphas.shape[0] * permutation_len, alph_count))\n",
    "for _, i in enumerate(alphas):\n",
    "    full_alphas[_*permutation_len : (_+1)*permutation_len, :] = np.asarray(list(permutations(i, alph_count)))\n",
    "    \n",
    "full_alphas = full_alphas / step_size\n",
    "full_alphas = np.unique(full_alphas, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82afa75a",
   "metadata": {},
   "source": [
    "### 3. Brute Force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbed4cb",
   "metadata": {},
   "source": [
    "### 3. 1. candida_genetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da004290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff318b9d92b460886fbd6589bdb0ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt_partition, _ =  leidenalg.find_partition_multiplex(\n",
    "graphs_multiplex_ig['candida_genetic'],  # list из слоев графа в формате igraph\n",
    "leidenalg.ModularityVertexPartition,  # вставляем leidenalg.ModularityVertexPartition\n",
    "n_iterations=2, \n",
    "max_comm_size=0, \n",
    "seed=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nmi_arr = []\n",
    "net = graphs_multiplex_nx['candida_genetic']\n",
    "for alpha in tqdm(full_alphas):\n",
    "    adj_matrixes = [nx.adjacency_matrix(i, i.nodes()) for i in net]\n",
    "    alpha_adj_matrixes = [i*j for i,j in zip(adj_matrixes, alpha)]\n",
    "    \n",
    "    adj_for_graph = alpha_adj_matrixes[0]\n",
    "    for i in range(1, len(alpha_adj_matrixes)):\n",
    "        adj_for_graph += alpha_adj_matrixes[i]\n",
    "        \n",
    "    alpha_graph = nx.from_scipy_sparse_matrix(adj_for_graph, parallel_edges=False, edge_attribute='weight')\n",
    "    alpha_graph_ig = ig.Graph.from_networkx(alpha_graph)\n",
    "    \n",
    "    part = leidenalg.find_partition(alpha_graph_ig, leidenalg.ModularityVertexPartition);\n",
    "    part = from_part_to_list(part)\n",
    "    \n",
    "    nmi = normalized_mutual_info_score(gt_partition, part)\n",
    "    nmi_arr.append(nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "738e797c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9245790811463562"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(nmi_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2820e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_alphas = np.unique(full_alphas[np.nonzero(np.array(nmi_arr) == np.max(nmi_arr))], axis=0)[:100, :]\n",
    "fusion_k = max_alphas.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "559a0f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.1, 0.1, 0. , 0.1, 0.1, 0.5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_alphas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "585886c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9278145450421957\n",
      "0.30425818941391575\n",
      "0.2812681362121794\n",
      "0.6234527544161886\n"
     ]
    }
   ],
   "source": [
    "for net_name in graphs_multiplex_nx:\n",
    "    net = graphs_multiplex_nx[net_name]\n",
    "    \n",
    "    part_gt , _ =  leidenalg.find_partition_multiplex(\n",
    "    graphs_multiplex_ig[net_name],  # list из слоев графа в формате igraph\n",
    "    leidenalg.ModularityVertexPartition,  # вставляем leidenalg.ModularityVertexPartition\n",
    "    n_iterations=2, \n",
    "    max_comm_size=0, \n",
    "    seed=None)\n",
    "    \n",
    "    \n",
    "    ig_graph = fusion_graph(net, max_alphas[0])\n",
    "    part = leidenalg.find_partition(ig_graph, leidenalg.ModularityVertexPartition);\n",
    "    part = from_part_to_list(part)\n",
    "    \n",
    "    nmi = normalized_mutual_info_score(part_gt, part)\n",
    "    print(nmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd975aa",
   "metadata": {},
   "source": [
    "### 3.2. drosophila_genetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2931848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3baaf19d9045229163a3cdf65c2c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt_partition, _ =  leidenalg.find_partition_multiplex(\n",
    "graphs_multiplex_ig['drosophila_genetic'],  # list из слоев графа в формате igraph\n",
    "leidenalg.ModularityVertexPartition,  # вставляем leidenalg.ModularityVertexPartition\n",
    "n_iterations=2, \n",
    "max_comm_size=0, \n",
    "seed=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nmi_arr = []\n",
    "net = graphs_multiplex_nx['drosophila_genetic']\n",
    "for alpha in tqdm(full_alphas):\n",
    "    adj_matrixes = [nx.adjacency_matrix(i, i.nodes()) for i in net]\n",
    "    alpha_adj_matrixes = [i*j for i,j in zip(adj_matrixes, alpha)]\n",
    "    \n",
    "    adj_for_graph = alpha_adj_matrixes[0]\n",
    "    for i in range(1, len(alpha_adj_matrixes)):\n",
    "        adj_for_graph += alpha_adj_matrixes[i]\n",
    "        \n",
    "    alpha_graph = nx.from_scipy_sparse_matrix(adj_for_graph, parallel_edges=False, edge_attribute='weight')\n",
    "    alpha_graph_ig = ig.Graph.from_networkx(alpha_graph)\n",
    "    \n",
    "    part = leidenalg.find_partition(alpha_graph_ig, leidenalg.ModularityVertexPartition);\n",
    "    part = from_part_to_list(part)\n",
    "    \n",
    "    nmi = normalized_mutual_info_score(gt_partition, part)\n",
    "    nmi_arr.append(nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "589cd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_alphas = np.unique(full_alphas[np.nonzero(np.array(nmi_arr) == np.max(nmi_arr))], axis=0)[:100, :]\n",
    "fusion_k = max_alphas.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0.4, 0. , 0.1, 0.1, 0. , 0.1, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55e730bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4, 0. , 0.1, 0.1, 0. , 0.1, 0.3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa61fe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8068880094276362\n",
      "0.5371332694052983\n",
      "0.4720083219388514\n",
      "0.6082265736876056\n"
     ]
    }
   ],
   "source": [
    "for net_name in graphs_multiplex_nx:\n",
    "    net = graphs_multiplex_nx[net_name]\n",
    "    \n",
    "    part_gt , _ =  leidenalg.find_partition_multiplex(\n",
    "    graphs_multiplex_ig[net_name],  # list из слоев графа в формате igraph\n",
    "    leidenalg.ModularityVertexPartition,  # вставляем leidenalg.ModularityVertexPartition\n",
    "    n_iterations=2, \n",
    "    max_comm_size=0, \n",
    "    seed=None)\n",
    "    \n",
    "    \n",
    "    ig_graph = fusion_graph(net, fusion_k)\n",
    "    part = leidenalg.find_partition(ig_graph, leidenalg.ModularityVertexPartition);\n",
    "    part = from_part_to_list(part)\n",
    "    \n",
    "    nmi = normalized_mutual_info_score(part_gt, part)\n",
    "    print(nmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15c16ce",
   "metadata": {},
   "source": [
    "### 3.3. homo_genetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5475f20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cce5f45b65d4fcaa48c7bd2efeba0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-0e18a6515659>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0madj_for_graph\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0malpha_adj_matrixes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0malpha_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_scipy_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madj_for_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparallel_edges\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_attribute\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0malpha_graph_ig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_networkx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DNN_classes\\lib\\site-packages\\networkx\\convert_matrix.py\u001b[0m in \u001b[0;36mfrom_scipy_sparse_matrix\u001b[1;34m(A, parallel_edges, create_using, edge_attribute)\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNetworkXError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Adjacency matrix not square: nx,ny={A.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m     \u001b[1;31m# Make sure we get even the isolated nodes of the graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m     \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# Create an iterable over (u, v, w) triples and for each triple, add an\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m     \u001b[1;31m# edge from u to v with weight w.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DNN_classes\\lib\\site-packages\\networkx\\classes\\graph.py\u001b[0m in \u001b[0;36madd_nodes_from\u001b[1;34m(self, nodes_for_adding, **attr)\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madjlist_inner_dict_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m                     \u001b[0mattr_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_attr_dict_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m                     \u001b[0mattr_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gt_partition, _ =  leidenalg.find_partition_multiplex(\n",
    "graphs_multiplex_ig['homo_genetic'],  # list из слоев графа в формате igraph\n",
    "leidenalg.ModularityVertexPartition,  # вставляем leidenalg.ModularityVertexPartition\n",
    "n_iterations=2, \n",
    "max_comm_size=0, \n",
    "seed=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nmi_arr = []\n",
    "net = graphs_multiplex_nx['homo_genetic']\n",
    "for alpha in tqdm(full_alphas):\n",
    "    adj_matrixes = [nx.adjacency_matrix(i, i.nodes()) for i in net]\n",
    "    alpha_adj_matrixes = [i*j for i,j in zip(adj_matrixes, alpha)]\n",
    "    \n",
    "    adj_for_graph = alpha_adj_matrixes[0]\n",
    "    for i in range(1, len(alpha_adj_matrixes)):\n",
    "        adj_for_graph += alpha_adj_matrixes[i]\n",
    "        \n",
    "    alpha_graph = nx.from_scipy_sparse_matrix(adj_for_graph, parallel_edges=False, edge_attribute='weight')\n",
    "    alpha_graph_ig = ig.Graph.from_networkx(alpha_graph)\n",
    "    \n",
    "    part = leidenalg.find_partition(alpha_graph_ig, leidenalg.ModularityVertexPartition);\n",
    "    part = from_part_to_list(part)\n",
    "    \n",
    "    nmi = normalized_mutual_info_score(gt_partition, part)\n",
    "    nmi_arr.append(nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a3f5881",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_alphas = np.unique(full_alphas[np.nonzero(np.array(nmi_arr) == np.max(nmi_arr))], axis=0)[:100, :]\n",
    "fusion_k = max_alphas.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "25115ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0.7, 0.2, 0. , 0.1, 0. ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d84ac107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4458520288581317\n",
      "0.5430034943830734\n",
      "0.4890599368349828\n",
      "0.6088496749480669\n"
     ]
    }
   ],
   "source": [
    "for net_name in graphs_multiplex_nx:\n",
    "    net = graphs_multiplex_nx[net_name]\n",
    "    \n",
    "    part_gt , _ =  leidenalg.find_partition_multiplex(\n",
    "    graphs_multiplex_ig[net_name],  # list из слоев графа в формате igraph\n",
    "    leidenalg.ModularityVertexPartition,  # вставляем leidenalg.ModularityVertexPartition\n",
    "    n_iterations=2, \n",
    "    max_comm_size=0, \n",
    "    seed=None)\n",
    "    \n",
    "    \n",
    "    ig_graph = fusion_graph(net, max_alphas[0])\n",
    "    part = leidenalg.find_partition(ig_graph, leidenalg.ModularityVertexPartition);\n",
    "    part = from_part_to_list(part)\n",
    "    \n",
    "    nmi = normalized_mutual_info_score(part_gt, part)\n",
    "    print(nmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e206c5",
   "metadata": {},
   "source": [
    "### 3.4. mus_genetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7024d1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e98380de9940a2b58b36e2facad170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt_partition, _ =  leidenalg.find_partition_multiplex(\n",
    "graphs_multiplex_ig['mus_genetic'],  # list из слоев графа в формате igraph\n",
    "leidenalg.ModularityVertexPartition,  # вставляем leidenalg.ModularityVertexPartition\n",
    "n_iterations=2, \n",
    "max_comm_size=0, \n",
    "seed=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nmi_arr = []\n",
    "net = graphs_multiplex_nx['mus_genetic']\n",
    "for alpha in tqdm(full_alphas):\n",
    "    adj_matrixes = [nx.adjacency_matrix(i, i.nodes()) for i in net]\n",
    "    alpha_adj_matrixes = [i*j for i,j in zip(adj_matrixes, alpha)]\n",
    "    \n",
    "    adj_for_graph = alpha_adj_matrixes[0]\n",
    "    for i in range(1, len(alpha_adj_matrixes)):\n",
    "        adj_for_graph += alpha_adj_matrixes[i]\n",
    "        \n",
    "    alpha_graph = nx.from_scipy_sparse_matrix(adj_for_graph, parallel_edges=False, edge_attribute='weight')\n",
    "    alpha_graph_ig = ig.Graph.from_networkx(alpha_graph)\n",
    "    \n",
    "    part = leidenalg.find_partition(alpha_graph_ig, leidenalg.ModularityVertexPartition);\n",
    "    part = from_part_to_list(part)\n",
    "    \n",
    "    nmi = normalized_mutual_info_score(gt_partition, part)\n",
    "    nmi_arr.append(nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "591bdafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_alphas = np.unique(full_alphas[np.nonzero(np.array(nmi_arr) == np.max(nmi_arr))], axis=0)[:100, :]\n",
    "fusion_k = max_alphas.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3738b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0.1, 0.1, 0.2, 0.2, 0.1, 0.2]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f530e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9658820045140976\n",
      "0.3141744387619212\n",
      "0.2622125390314791\n",
      "0.6348276593018142\n"
     ]
    }
   ],
   "source": [
    "for net_name in graphs_multiplex_nx:\n",
    "    net = graphs_multiplex_nx[net_name]\n",
    "    \n",
    "    part_gt , _ =  leidenalg.find_partition_multiplex(\n",
    "    graphs_multiplex_ig[net_name],  # list из слоев графа в формате igraph\n",
    "    leidenalg.ModularityVertexPartition,  # вставляем leidenalg.ModularityVertexPartition\n",
    "    n_iterations=2, \n",
    "    max_comm_size=0, \n",
    "    seed=None)\n",
    "    \n",
    "    \n",
    "    ig_graph = fusion_graph(net, fusion_k)\n",
    "    part = leidenalg.find_partition(ig_graph, leidenalg.ModularityVertexPartition);\n",
    "    part = from_part_to_list(part)\n",
    "    \n",
    "    nmi = normalized_mutual_info_score(part_gt, part)\n",
    "    print(nmi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
